{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 필요 구성 라이브러리 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2022-10-21 09:38:12.181760: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Collecting ko-core-news-sm==3.4.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/ko_core_news_sm-3.4.0/ko_core_news_sm-3.4.0-py3-none-any.whl (14.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in ./.env/lib/python3.9/site-packages (from ko-core-news-sm==3.4.0) (3.4.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in ./.env/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->ko-core-news-sm==3.4.0) (3.0.10)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./.env/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->ko-core-news-sm==3.4.0) (2.4.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in ./.env/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->ko-core-news-sm==3.4.0) (1.23.4)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./.env/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->ko-core-news-sm==3.4.0) (2.0.8)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./.env/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->ko-core-news-sm==3.4.0) (1.0.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./.env/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->ko-core-news-sm==3.4.0) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in ./.env/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->ko-core-news-sm==3.4.0) (8.1.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./.env/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->ko-core-news-sm==3.4.0) (2.0.7)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./.env/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->ko-core-news-sm==3.4.0) (4.64.1)\n",
      "Requirement already satisfied: setuptools in ./.env/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->ko-core-news-sm==3.4.0) (58.1.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in ./.env/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->ko-core-news-sm==3.4.0) (0.10.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./.env/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->ko-core-news-sm==3.4.0) (1.0.9)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in ./.env/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->ko-core-news-sm==3.4.0) (0.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.env/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->ko-core-news-sm==3.4.0) (21.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./.env/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->ko-core-news-sm==3.4.0) (3.3.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./.env/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->ko-core-news-sm==3.4.0) (2.28.1)\n",
      "Requirement already satisfied: jinja2 in ./.env/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->ko-core-news-sm==3.4.0) (3.1.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in ./.env/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->ko-core-news-sm==3.4.0) (1.10.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in ./.env/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->ko-core-news-sm==3.4.0) (0.6.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in ./.env/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->ko-core-news-sm==3.4.0) (3.0.9)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in ./.env/lib/python3.9/site-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->ko-core-news-sm==3.4.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in ./.env/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->ko-core-news-sm==3.4.0) (4.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.env/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->ko-core-news-sm==3.4.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./.env/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->ko-core-news-sm==3.4.0) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in ./.env/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->ko-core-news-sm==3.4.0) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.env/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->ko-core-news-sm==3.4.0) (2022.9.24)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./.env/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->ko-core-news-sm==3.4.0) (0.0.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in ./.env/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->ko-core-news-sm==3.4.0) (0.7.9)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in ./.env/lib/python3.9/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->ko-core-news-sm==3.4.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.env/lib/python3.9/site-packages (from jinja2->spacy<3.5.0,>=3.4.0->ko-core-news-sm==3.4.0) (2.1.1)\n",
      "Installing collected packages: ko-core-news-sm\n",
      "Successfully installed ko-core-news-sm-3.4.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('ko_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "# !pip install --upgrade pip\n",
    "# !pip install konlpy\n",
    "# !pip install nltk\n",
    "# !pip install sklearn\n",
    "# !pip install pandas\n",
    "# !pip install jellyfish\n",
    "# !pip install segtok\n",
    "# !pip install networkx\n",
    "# !pip install matplotlib\n",
    "# !pip install tensorflow\n",
    "# !pip install krwordrank\n",
    "# !pip install soynlp\n",
    "# !pip install textrank\n",
    "# !pip install sentence_transformers\n",
    "# !pip install spaCy\n",
    "# !python -m spacy download ko_core_news_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텍스트 마이닝 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요 라이브러리 선언\n",
    "from pprint import pprint\n",
    "\n",
    "from yake import korea_token\n",
    "from yake.korea_token import edit_josa, edit_sentences\n",
    "import math\n",
    "\n",
    "from konlpy.tag import Komoran\n",
    "from collections import Counter\n",
    "\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "from math import log\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request\n",
    "np.random.seed(seed=0)\n",
    "\n",
    "from krwordrank.word import KRWordRank\n",
    "from krwordrank.sentence import summarize_with_sentences\n",
    "from krwordrank.word import summarize_with_keywords\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from soynlp.tokenizer import MaxScoreTokenizer\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "import networkx\n",
    "\n",
    "# from textrank import KeywordSummarizer\n",
    "\n",
    "import itertools\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.ko.stop_words import STOP_WORDS\n",
    "from string import punctuation\n",
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "komoran = Komoran()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "STRTexT = \"러시아가 우크라이나 키이우 등을 공습한 것은 군 내부 비판과 블라디미르 푸틴 러시아 대통령의 자존심 때문이라는 분석이 나왔다. 영국 가디언지는 10일(현지시간) 푸틴 대통령의 대규모 공습은 국내 군 비판세력, 러시아가 침공에서 실패하고 있다는 사실, 크림대교 폭발 후 상처받은 자존심에 대한 절박한 답변이라고 풀이했다. 가디언에 따르면 미국 싱크탱크 카네기국제평화재단의 선임 연구원 안드레이 콜레스니코프는 '지금 푸틴이 하는 것은 사소한 복수'라며 '개인적 복수도 있다'고 말했다. 러시아 전쟁 전문가와 군사 블로거 등은 수개월간 우크라이나를 상대로 전면전을 벌이라고 촉구해왔고 키이우 등의 거리에 시신이 있는 끔찍한 사진이 나오자 지금은 만족해한다. 최근 러시아군 수뇌부를 비판했던 람잔 카디로프 체첸 공화국 수장은 '(볼로디미르) 젤렌스키(우크라이나 대통령), 우리는 러시아가 아직 제대로 시작도 안했다고 경고했다'라며 '이제 전쟁 진행에 100% 만족한다'고 말했다. 푸틴 대통령은 이날 러시아 안전보장이사회 회의를 주재하고 크림대교 폭발의 배후로 우크라이나 정보 당국을 겨냥하면서 '이런 종류의 범죄에 대응을 하지 않는 것은 불가능하다'고 말했다. 그러나 드미트로 쿨레바 우크라이나 외무장관은 '러시아는 크림대교 사건 전에도 우크라이나에 계속 미사일 공격을 했다'며 '푸틴은 전투 패배로 절박한 상황이며 전황을 유리하게 바꾸려고 미사일 공포를 사용한다'고 반박했다. 우크라이나 구조대원들이 10일(현지시간) 수도 키이우 시내에서 러시아군의 미사일 공격을 당한 현장을 조사하고 있다. 이날 오전에 키이우 시내에 여러차례 폭발이 발생했다. 푸틴 대통령은 이번 공격이 국방부의 요청에 따라 이뤄졌다고 주장했는데, 이것이 사실이라면 이는 새로운 합동군 총사령관 세르게이 수로비킨의 첫번째 결정이라고 가디언은 전했다. 수로비킨 사령관과 함께 일했던 전 국방부 관계자는 가디언지에 '오늘 키이우에서 벌어진 일이 놀랍지 않았다. 그는 매우 무자비하고 사람 목숨을 신경 쓰지 않는다'며 '그의 손이 우크라이나인의 피로 뒤덮일까 걱정된다'고 말했다. 그러나 푸틴 대통령이 이날 공습으로 얻은 매파들의 호평은 오래가지 않을 수 있다. 그는 이번과 같은 대규모 미사일 공격은 러시아 영토 공격 시 대응으로 남겨둘 것이라고 말했는데 강경파들은 전면전을 원하고 있다. 정치 평론가인 세르게이 마르코프는 '러시아 여론은 대규모 공격과 우크라이나군이 사용할 가능성이 있는 인프라 완전파괴를 원한다'고 말했다. 한편으론 비판 세력의 목소리는 그다지 의미가 없을 수도 있어 보인다. 전쟁과 관련한 의사결정 과정은 여전히 불투명하다. 콜레스니코프 선임 연구원은 '푸틴 대통령으로선 매파와 극보수파의 불만에 대응하는 것이 중요하겠지만 나는 그들의 영향력을 과장하진 않을 것'이라며 '푸틴 자신이 가장 매파적이고 극보수적인 인물'이라고 말했다. 러시아에서 나오는 한 가지 이론은 푸틴 대통령이 악명 높은 새로운 군사령관을 임명함으로써 전쟁에서 국방부의 성과에 대한 분노를 줄이려고 한다는 것이다. 수로비킨 사령관과 2020년까지 함께 일했던 전 공군 중위인 글렙 이리소프는 '수로비킨은 강경파들을 선호하고 와그너 용병회사와도 좋은 관계를 유지한다'며 '그러나 그가 매우 잔인한 동시에 유능한 사령관이지만 모든 문제를 풀 수는 없을 것'이라고 말했다.\"\n",
    "LISTText = [\"러시아가 우크라이나 키이우 등을 공습한 것은 군 내부 비판과 블라디미르 푸틴 러시아 대통령의 자존심 때문이라는 분석이 나왔다.\",\n",
    "            \"영국 가디언지는 10일(현지시간) 푸틴 대통령의 대규모 공습은 국내 군 비판세력, 러시아가 침공에서 실패하고 있다는 사실, 크림대교 폭발 후 상처받은 자존심에 대한 절박한 답변이라고 풀이했다.\",\n",
    "            \"가디언에 따르면 미국 싱크탱크 카네기국제평화재단의 선임 연구원 안드레이 콜레스니코프는 '지금 푸틴이 하는 것은 사소한 복수'라며 '개인적 복수도 있다'고 말했다.\",\n",
    "            \"러시아 전쟁 전문가와 군사 블로거 등은 수개월간 우크라이나를 상대로 전면전을 벌이라고 촉구해왔고 키이우 등의 거리에 시신이 있는 끔찍한 사진이 나오자 지금은 만족해한다.\",\n",
    "            \"최근 러시아군 수뇌부를 비판했던 람잔 카디로프 체첸 공화국 수장은 '(볼로디미르) 젤렌스키(우크라이나 대통령), 우리는 러시아가 아직 제대로 시작도 안했다고 경고했다'라며 '이제 전쟁 진행에 100% 만족한다'고 말했다.\",\n",
    "            \"푸틴 대통령은 이날 러시아 안전보장이사회 회의를 주재하고 크림대교 폭발의 배후로 우크라이나 정보 당국을 겨냥하면서 '이런 종류의 범죄에 대응을 하지 않는 것은 불가능하다'고 말했다.\",\n",
    "            \"그러나 드미트로 쿨레바 우크라이나 외무장관은 '러시아는 크림대교 사건 전에도 우크라이나에 계속 미사일 공격을 했다'며 '푸틴은 전투 패배로 절박한 상황이며 전황을 유리하게 바꾸려고 미사일 공포를 사용한다'고 반박했다.\",\n",
    "            \"우크라이나 구조대원들이 10일(현지시간) 수도 키이우 시내에서 러시아군의 미사일 공격을 당한 현장을 조사하고 있다.\",\n",
    "            \"이날 오전에 키이우 시내에 여러차례 폭발이 발생했다.\",\n",
    "            \"푸틴 대통령은 이번 공격이 국방부의 요청에 따라 이뤄졌다고 주장했는데, 이것이 사실이라면 이는 새로운 합동군 총사령관 세르게이 수로비킨의 첫번째 결정이라고 가디언은 전했다.\",\n",
    "            \"수로비킨 사령관과 함께 일했던 전 국방부 관계자는 가디언지에 '오늘 키이우에서 벌어진 일이 놀랍지 않았다.\",\n",
    "            \"그는 매우 무자비하고 사람 목숨을 신경 쓰지 않는다'며 '그의 손이 우크라이나인의 피로 뒤덮일까 걱정된다'고 말했다.\",\n",
    "            \"그러나 푸틴 대통령이 이날 공습으로 얻은 매파들의 호평은 오래가지 않을 수 있다.\",\n",
    "            \"그는 이번과 같은 대규모 미사일 공격은 러시아 영토 공격 시 대응으로 남겨둘 것이라고 말했는데 강경파들은 전면전을 원하고 있다.\",\n",
    "            \"정치 평론가인 세르게이 마르코프는 '러시아 여론은 대규모 공격과 우크라이나군이 사용할 가능성이 있는 인프라 완전파괴를 원한다'고 말했다.\",\n",
    "            \"한편으론 비판 세력의 목소리는 그다지 의미가 없을 수도 있어 보인다.\",\n",
    "            \"전쟁과 관련한 의사결정 과정은 여전히 불투명하다.\",\n",
    "            \"콜레스니코프 선임 연구원은 '푸틴 대통령으로선 매파와 극보수파의 불만에 대응하는 것이 중요하겠지만 나는 그들의 영향력을 과장하진 않을 것'이라며 '푸틴 자신이 가장 매파적이고 극보수적인 인물'이라고 말했다.\",\n",
    "            \"러시아에서 나오는 한 가지 이론은 푸틴 대통령이 악명 높은 새로운 군사령관을 임명함으로써 전쟁에서 국방부의 성과에 대한 분노를 줄이려고 한다는 것이다.\",\n",
    "            \"수로비킨 사령관과 2020년까지 함께 일했던 전 공군 중위인 글렙 이리소프는 '수로비킨은 강경파들을 선호하고 와그너 용병회사와도 좋은 관계를 유지한다'며 '그러나 그가 매우 잔인한 동시에 유능한 사령관이지만 모든 문제를 풀 수는 없을 것'이라고 말했다.\"\n",
    "        ]\n",
    "\n",
    "\n",
    "# new_text = edit_sentences(STRTexT)\n",
    "# # print('원본 split_sentences :', new_text)\n",
    "# total_value = []\n",
    "# for x in range(len(new_text)):\n",
    "#     total_value.append(' '.join(edit_josa(new_text[x])))\n",
    "\n",
    "# print(total_value)\n",
    "TUNNEDText = ['러시아 우크라이나 키이우 등 공습 것 군 내부 비판 블라디미르 푸틴 러시아 대통령 자존심 때문 분석 나오',\n",
    "              '영국 가디언지 10일 현지시간 푸틴 대통령 대규모 공습 국내 군 비판세력 러시아 침공 실패 있 사실 크림대교 폭발 후 상처 자존심 대하 절박 답변 풀이',\n",
    "              '가디언 따르 미국 싱크탱크 카네기국제평화재단 선임 연구원 안드레이 콜레스니코프 지금 푸틴 하 것 사소 복수 이 개인 복수 있 고 말',\n",
    "              '러시아 전쟁 전문가 군사 블로거 등 수개월간 우크라이나 상대로 전면전 벌이 촉구 키이우 등 거리 시신 있 끔찍 사진 나오 지금 만족',\n",
    "              '최근 러시아군 수뇌부 비판 람잔 카디로프 체첸 공화국 수장 보 젤렌스 우크라이나 대통령 우리 러시아 아직 제대로 시작 안 경고 이 이제 전쟁 진행 100 만족 고 말',\n",
    "              '푸틴 대통령 이날 러시아 안전보장 회의 주재 크림대교 폭발 배후 우크라이나 정보 당국 겨냥 이런 종류 범죄 대응 하 않 것 불가능 고 말',\n",
    "              '그러나 드미트 쿨레바 우크라이나 외무장관 러시아 크림대교 사건 전 우크라이나 계속 미사일 공격 하 이 푸틴 전투 패배 절박 상황 전황 유리 바꾸 미사일 공포 사용 고 반박',\n",
    "              '우크라이나 구조대원 10일 현지시간 수 키이우 시내 러시아군 미사일 공격 당하 현장 조사 있',\n",
    "              '이날 오전 키이우 시내 여러차례 폭발 발생', \n",
    "              '푸틴 대통령 이번 공격 국방부 요청 따르 이루어지 주장 이것 사실 이 새롭 합동군 총사령관 세르 수로비킨 첫번 결정 가디언 전하', \n",
    "              '수로비킨 사령관 함께 일 전 국방부 관계자 가디언지 오늘 키이우 벌어지 일 놀랍 않', \n",
    "              '그 매우 무자비 사람 목숨 신경 쓰 않 이 그 손 우크라이나인 피로 뒤덮이 걱정 고 말', \n",
    "              '그러나 푸틴 대통령 이날 공습 얻 매파 호평 오래가 않 수 있', \n",
    "              '그 이번 같 대규모 미사일 공격 러시아 영토 공격 시 대응 남기 것 말 강경파 전면전 원하 있', \n",
    "              '정치 평론가 세르 마르코프 러시아 여론 대규모 공격 우크라이나군 사용 가능 있 인프라 완전파괴 원하 고 말', \n",
    "              '한편 비판 세력 목소리 그다지 의미 없 수 있 보이', \n",
    "              '전쟁 관련 의사결정 과정 여전히 불투명', \n",
    "              '콜레스니코프 선임 연구원 푸틴 대통령 매파 극보수파 불만 대응 것 중요 나 그 영향력 과장하진 않 것 이 푸틴 자신 가장 매파 극보수 인물 이 말', \n",
    "              '러시아 나오 한 가지 이론 푸틴 대통령 악명 높 새롭 군사령관 임명 전쟁 국방부 성과 대하 분노 줄이 하 것', \n",
    "              '수로비킨 사령관 2020년 함께 일 전 공군 중위 글렙 이리소프 수로비킨 강경파 선호 오 용병회사 좋 관계 유지 이 그러나 그 매우 잔인 동시 유능 사령관 모든 문제 풀 수 없 것 이 말']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "빈도수 기반 명사 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Komoran 기준 : ('러시아', 10)\n",
      "Komoran 기준 : ('푸틴', 9)\n",
      "Komoran 기준 : ('우크라이나', 8)\n",
      "Komoran 기준 : ('대통령', 8)\n",
      "Komoran 기준 : ('공격', 6)\n",
      "Komoran 기준 : ('비판', 4)\n",
      "Komoran 기준 : ('가디언', 4)\n",
      "Komoran 기준 : ('전쟁', 4)\n",
      "Komoran 기준 : ('미사일', 4)\n",
      "Komoran 기준 : ('수로', 4)\n",
      "Komoran 기준 : ('비킨', 4)\n",
      "Komoran 기준 : ('이우', 3)\n",
      "Komoran 기준 : ('공습', 3)\n"
     ]
    }
   ],
   "source": [
    "# STRTexT에서 명사를 추출, 명사의 수를 count로 선언\n",
    "noun = komoran.nouns(STRTexT)\n",
    "count = Counter(noun)\n",
    "\n",
    "# 명사 빈도 카운트\n",
    "noun_list = count.most_common(20)\n",
    "for v in noun_list:\n",
    "    if len(v[0]) == 1:\n",
    "        pass\n",
    "    else:\n",
    "        print(\"Komoran 기준 : \" + str(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF.IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('러시아', 0.34349799588831337),\n",
      " ('내부', 0.33043401009471474),\n",
      " ('때문', 0.33043401009471474),\n",
      " ('분석', 0.33043401009471474),\n",
      " ('블라디미르', 0.33043401009471474),\n",
      " ('자존심', 0.2904565526794969),\n",
      " ('공습', 0.2620920952438779),\n",
      " ('나오', 0.2620920952438779),\n",
      " ('비판', 0.2620920952438779),\n",
      " ('키이우', 0.22211463782865998),\n",
      " ('우크라이나', 0.20691591390621303),\n",
      " ('대통령', 0.1821371804134421),\n",
      " ('푸틴', 0.17174899794415668),\n",
      " ('100', 0.0),\n",
      " ('10일', 0.0),\n",
      " ('2020년', 0.0),\n",
      " ('가능', 0.0),\n",
      " ('가디언', 0.0),\n",
      " ('가디언지', 0.0),\n",
      " ('가장', 0.0)]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(TUNNEDText)\n",
    "matrix = vectorizer.transform(TUNNEDText)\n",
    "\n",
    "vocabulary_word_id = defaultdict(int)\n",
    "    \n",
    "for idx, token in enumerate(vectorizer.get_feature_names()):\n",
    "    vocabulary_word_id[token] = idx\n",
    "    \n",
    "# 특징 추출 결과: {\"token\": value}\n",
    "result = defaultdict(str)\n",
    "    \n",
    "for token in vectorizer.get_feature_names():\n",
    "    result[token] = matrix[0, vocabulary_word_id[token]]\n",
    "    \n",
    "# 내림차순 (중요도 high) 기준 정렬\n",
    "result = sorted(result.items(), key = lambda item: item[1], reverse = True)\n",
    "pprint(result[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('회의', 197),\n",
       " ('호평', 196),\n",
       " ('현지시간', 195),\n",
       " ('현장', 194),\n",
       " ('합동군', 193),\n",
       " ('함께', 192),\n",
       " ('한편', 191),\n",
       " ('피로', 190),\n",
       " ('풀이', 189),\n",
       " ('푸틴', 188),\n",
       " ('폭발', 187),\n",
       " ('평론가', 186),\n",
       " ('패배', 185),\n",
       " ('키이우', 184),\n",
       " ('크림대교', 183),\n",
       " ('쿨레바', 182),\n",
       " ('콜레스니코프', 181),\n",
       " ('카디로프', 180),\n",
       " ('카네기국제평화재단', 179),\n",
       " ('침공', 178)]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countList = []\n",
    "\n",
    "tfidfv = TfidfVectorizer().fit(TUNNEDText)\n",
    "\n",
    "for k,v in tfidfv.vocabulary_.items():\n",
    "    textTuple = ((k, v))\n",
    "    countList.append(textTuple)\n",
    "\n",
    "countList.sort(reverse=True)\n",
    "countList[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10% 요약 결과:  최근 러시아군 수뇌부를 비판했던 람잔 카디로프 체첸 공화국 수장은 '(볼로디미르) 젤렌스키(우크라이나 대통령), 우리는 러시아가 아직 제대로 시작도 안했다고 경고했다'라며 '이제 전쟁 진행에 100% 만족한다'고 말했다.그러나 드미트로 쿨레바 우크라이나 외무장관은 '러시아는 크림대교 사건 전에도 우크라이나에 계속 미사일 공격을 했다'며 '푸틴은 전투 패배로 절박한 상황이며 전황을 유리하게 바꾸려고 미사일 공포를 사용한다'고 반박했다.\n"
     ]
    }
   ],
   "source": [
    "# 원 예제는 영어를 입력 하면 번역 후 한국어로 출력되는 기능이 있음.\n",
    "# 이번에는 한국어를 입력했기 때문에 해당 기능이 사용되지 않음. (영어 입력하면 한국어 나오는지는 실험 하지 않음.)\n",
    "\n",
    "# 사용된 방식은 추상적 방법론을 사용해 만든 로직임. 추상적 방법론이란, 대상 문서의 의미를 해석하여 지능적으로 요약문을 만드는 방법으로, 완전히 새로운 문장을 생성함.\n",
    "# 다른 방식으로는 대상 문서에서 중요한 문장을 식별하여 요약문을 만드는 방법인 추출식 방법론이 있음.\n",
    "\n",
    "def summarize(text, per):\n",
    "    nlp = spacy.load('ko_core_news_sm')\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.text for token in doc]\n",
    "    word_frequencies = {}\n",
    "    for word in doc:\n",
    "        if word.text.lower() not in list(STOP_WORDS):\n",
    "            if word.text not in word_frequencies.keys():\n",
    "                word_frequencies[word.text] = 1\n",
    "            else:\n",
    "                word_frequencies[word.text] += 1\n",
    "    max_frequency = max(word_frequencies.values())\n",
    "    for word in word_frequencies.keys():\n",
    "        word_frequencies[word] = word_frequencies[word]/max_frequency\n",
    "    sentence_tokens = [sent for sent in doc.sents]\n",
    "    sentence_score = {}\n",
    "    for sent in sentence_tokens:\n",
    "        for word in sent:\n",
    "            if word.text.lower() in word_frequencies.keys():\n",
    "                if sent not in sentence_score.keys():\n",
    "                    sentence_score[sent] = word_frequencies[word.text.lower()]\n",
    "                else:\n",
    "                    sentence_score [sent] += word_frequencies[word.text.lower()]\n",
    "\n",
    "    select_length = int(len(sentence_tokens)*per)\n",
    "    summary=nlargest(select_length, sentence_score, key=sentence_score.get)\n",
    "    final_summary = [word.text for word in summary]\n",
    "    summary = ''.join(final_summary)\n",
    "    return summary\n",
    "\n",
    "summarized_text = summarize(STRTexT, 0.1)\n",
    "print('10% 요약 결과: ', summarized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Text Summarization With Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 해당 기능은 기계학습이 필요하기 때문에 후순위로 선정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TextRank Based on Sentence Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 해당 기능은 기계학습이 필요하기 때문에 후순위로 선정한다.\n",
    "\n",
    "\n",
    "# Glove를 활용한 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WordRank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* KR-WordRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'푸틴': 1.3732243555746098, '대통령': 1.3521268801052138, '러시아': 1.3020997627605881, '우크': 1.1216525136431523, '공격': 1.0979590292080694, '키이': 1.0581310608472447}\n"
     ]
    }
   ],
   "source": [
    "texts = TUNNEDText\n",
    "# texts = LISTText\n",
    "wordrank_extractor = KRWordRank(min_count=5, max_length=10)\n",
    "keywords, rank, graph = wordrank_extractor.extract(texts, num_keywords=100)\n",
    "\n",
    "def make_vocab_score(keywords, scaling=None):\n",
    "    if scaling is None:\n",
    "        scaling = lambda x:math.sqrt(x)\n",
    "    return {word:scaling(rank) for word, rank in keywords.items()}\n",
    "\n",
    "keywords = make_vocab_score(keywords)\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* sentence extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"푸틴 대통령은 이날 러시아 안전보장이사회 회의를 주재하고 크림대교 폭발의 배후로 우크라이나 정보 당국을 겨냥하면서 '이런 종류의 범죄에 대응을 하지 않는 것은 불가능하다'고 말했다.\", \"정치 평론가인 세르게이 마르코프는 '러시아 여론은 대규모 공격과 우크라이나군이 사용할 가능성이 있는 인프라 완전파괴를 원한다'고 말했다.\", '영국 가디언지는 10일(현지시간) 푸틴 대통령의 대규모 공습은 국내 군 비판세력, 러시아가 침공에서 실패하고 있다는 사실, 크림대교 폭발 후 상처받은 자존심에 대한 절박한 답변이라고 풀이했다.', \"가디언에 따르면 미국 싱크탱크 카네기국제평화재단의 선임 연구원 안드레이 콜레스니코프는 '지금 푸틴이 하는 것은 사소한 복수'라며 '개인적 복수도 있다'고 말했다.\", '우크라이나 구조대원들이 10일(현지시간) 수도 키이우 시내에서 러시아군의 미사일 공격을 당한 현장을 조사하고 있다.', '푸틴 대통령은 이번 공격이 국방부의 요청에 따라 이뤄졌다고 주장했는데, 이것이 사실이라면 이는 새로운 합동군 총사령관 세르게이 수로비킨의 첫번째 결정이라고 가디언은 전했다.', \"수로비킨 사령관과 2020년까지 함께 일했던 전 공군 중위인 글렙 이리소프는 '수로비킨은 강경파들을 선호하고 와그너 용병회사와도 좋은 관계를 유지한다'며 '그러나 그가 매우 잔인한 동시에 유능한 사령관이지만 모든 문제를 풀 수는 없을 것'이라고 말했다.\", '이날 오전에 키이우 시내에 여러차례 폭발이 발생했다.', '한편으론 비판 세력의 목소리는 그다지 의미가 없을 수도 있어 보인다.', '전쟁과 관련한 의사결정 과정은 여전히 불투명하다.']\n"
     ]
    }
   ],
   "source": [
    "texts = LISTText\n",
    "keywords, sents = summarize_with_sentences(texts, num_keywords=100, num_keysents=10)\n",
    "print(sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TextRank "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawSentence:\n",
    "    def __init__(self, textIter):\n",
    "        if type(textIter) == str: self.textIter = textIter.split('\\n')\n",
    "        else: self.textIter = textIter\n",
    "        self.rgxSplitter = re.compile('([.!?:](?:[\"\\']|(?![0-9])))')\n",
    " \n",
    "    def __iter__(self):\n",
    "        for line in self.textIter:\n",
    "            ch = self.rgxSplitter.split(line)\n",
    "            for s in map(lambda a, b: a + b, ch[::2], ch[1::2]):\n",
    "                if not s: continue\n",
    "                yield s\n",
    " \n",
    "class RawSentenceReader:\n",
    "    def __init__(self, filepath):\n",
    "        self.filepath = filepath\n",
    "        self.rgxSplitter = re.compile('([.!?:](?:[\"\\']|(?![0-9])))')\n",
    " \n",
    "    def __iter__(self):\n",
    "        for line in open(self.filepath, encoding='utf-8'):\n",
    "            ch = self.rgxSplitter.split(line)\n",
    "            for s in map(lambda a, b: a + b, ch[::2], ch[1::2]):\n",
    "                if not s: continue\n",
    "                yield s\n",
    " \n",
    "class RawTagger:\n",
    "    def __init__(self, textIter, tagger = None):\n",
    "        if tagger:\n",
    "            self.tagger = tagger\n",
    "        else :\n",
    "            from konlpy.tag import Komoran\n",
    "            self.tagger = Komoran()\n",
    "        if type(textIter) == str: self.textIter = textIter.split('\\n')\n",
    "        else: self.textIter = textIter\n",
    "        self.rgxSplitter = re.compile('([.!?:](?:[\"\\']|(?![0-9])))')\n",
    " \n",
    "    def __iter__(self):\n",
    "        for line in self.textIter:\n",
    "            ch = self.rgxSplitter.split(line)\n",
    "            for s in map(lambda a,b:a+b, ch[::2], ch[1::2]):\n",
    "                if not s: continue\n",
    "                yield self.tagger.pos(s)\n",
    " \n",
    "class RawTaggerReader:\n",
    "    def __init__(self, filepath, tagger = None):\n",
    "        if tagger:\n",
    "            self.tagger = tagger\n",
    "        else :\n",
    "            from konlpy.tag import Komoran\n",
    "            self.tagger = Komoran()\n",
    "        self.filepath = filepath\n",
    "        self.rgxSplitter = re.compile('([.!?:](?:[\"\\']|(?![0-9])))')\n",
    " \n",
    "    def __iter__(self):\n",
    "        for line in open(self.filepath, encoding='utf-8'):\n",
    "            ch = self.rgxSplitter.split(line)\n",
    "            for s in map(lambda a,b:a+b, ch[::2], ch[1::2]):\n",
    "                if not s: continue\n",
    "                yield self.tagger.pos(s)\n",
    " \n",
    "class TextRank:\n",
    "    def __init__(self, **kargs):\n",
    "        self.graph = None\n",
    "        self.window = kargs.get('window', 5)\n",
    "        self.coef = kargs.get('coef', 1.0)\n",
    "        self.threshold = kargs.get('threshold', 0.005)\n",
    "        self.dictCount = {}\n",
    "        self.dictBiCount = {}\n",
    "        self.dictNear = {}\n",
    "        self.nTotal = 0\n",
    " \n",
    " \n",
    "    def load(self, sentenceIter, wordFilter = None):\n",
    "        def insertPair(a, b):\n",
    "            if a > b: a, b = b, a\n",
    "            elif a == b: return\n",
    "            self.dictBiCount[a, b] = self.dictBiCount.get((a, b), 0) + 1\n",
    " \n",
    "        def insertNearPair(a, b):\n",
    "            self.dictNear[a, b] = self.dictNear.get((a, b), 0) + 1\n",
    " \n",
    "        for sent in sentenceIter:\n",
    "            for i, word in enumerate(sent):\n",
    "                if wordFilter and not wordFilter(word): continue\n",
    "                self.dictCount[word] = self.dictCount.get(word, 0) + 1\n",
    "                self.nTotal += 1\n",
    "                if i - 1 >= 0 and (not wordFilter or wordFilter(sent[i-1])): insertNearPair(sent[i-1], word)\n",
    "                if i + 1 < len(sent) and (not wordFilter or wordFilter(sent[i+1])): insertNearPair(word, sent[i+1])\n",
    "                for j in range(i+1, min(i+self.window+1, len(sent))):\n",
    "                    if wordFilter and not wordFilter(sent[j]): continue\n",
    "                    if sent[j] != word: insertPair(word, sent[j])\n",
    " \n",
    "    def loadSents(self, sentenceIter, tokenizer = None):\n",
    "        import math\n",
    "        def similarity(a, b):\n",
    "            n = len(a.intersection(b))\n",
    "            return n / float(len(a) + len(b) - n) / (math.log(len(a)+1) * math.log(len(b)+1))\n",
    " \n",
    "        if not tokenizer: rgxSplitter = re.compile('[\\\\s.,:;-?!()\"\\']+')\n",
    "        sentSet = []\n",
    "        for sent in filter(None, sentenceIter):\n",
    "            if type(sent) == str:\n",
    "                if tokenizer: s = set(filter(None, tokenizer(sent)))\n",
    "                else: s = set(filter(None, rgxSplitter.split(sent)))\n",
    "            else: s = set(sent)\n",
    "            if len(s) < 2: continue\n",
    "            self.dictCount[len(self.dictCount)] = sent\n",
    "            sentSet.append(s)\n",
    " \n",
    "        for i in range(len(self.dictCount)):\n",
    "            for j in range(i+1, len(self.dictCount)):\n",
    "                s = similarity(sentSet[i], sentSet[j])\n",
    "                if s < self.threshold: continue\n",
    "                self.dictBiCount[i, j] = s\n",
    " \n",
    "    def getPMI(self, a, b):\n",
    "        import math\n",
    "        co = self.dictNear.get((a, b), 0)\n",
    "        if not co: return None\n",
    "        return math.log(float(co) * self.nTotal / self.dictCount[a] / self.dictCount[b])\n",
    " \n",
    "    def getI(self, a):\n",
    "        import math\n",
    "        if a not in self.dictCount: return None\n",
    "        return math.log(self.nTotal / self.dictCount[a])\n",
    " \n",
    "    def build(self):\n",
    "        self.graph = networkx.Graph()\n",
    "        self.graph.add_nodes_from(self.dictCount.keys())\n",
    "        for (a, b), n in self.dictBiCount.items():\n",
    "            self.graph.add_edge(a, b, weight=n*self.coef + (1-self.coef))\n",
    " \n",
    "    def rank(self):\n",
    "        return networkx.pagerank(self.graph, weight='weight')\n",
    " \n",
    "    def extract(self, ratio = 0.1):\n",
    "        ranks = self.rank()\n",
    "        cand = sorted(ranks, key=ranks.get, reverse=True)[:int(len(ranks) * ratio)]\n",
    "        pairness = {}\n",
    "        startOf = {}\n",
    "        tuples = {}\n",
    "        for k in cand:\n",
    "            tuples[(k,)] = self.getI(k) * ranks[k]\n",
    "            for l in cand:\n",
    "                if k == l: continue\n",
    "                pmi = self.getPMI(k, l)\n",
    "                if pmi: pairness[k, l] = pmi\n",
    " \n",
    "        for (k, l) in sorted(pairness, key=pairness.get, reverse=True):\n",
    "            print(k[0], l[0], pairness[k, l])\n",
    "            if k not in startOf: startOf[k] = (k, l)\n",
    " \n",
    "        for (k, l), v in pairness.items():\n",
    "            pmis = v\n",
    "            rs = ranks[k] * ranks[l]\n",
    "            path = (k, l)\n",
    "            tuples[path] = pmis / (len(path) - 1) * rs ** (1 / len(path)) * len(path)\n",
    "            last = l\n",
    "            while last in startOf and len(path) < 7:\n",
    "                if last in path: break\n",
    "                pmis += pairness[startOf[last]]\n",
    "                last = startOf[last][1]\n",
    "                rs *= ranks[last]\n",
    "                path += (last,)\n",
    "                tuples[path] = pmis / (len(path) - 1) * rs ** (1 / len(path)) * len(path)\n",
    " \n",
    "        used = set()\n",
    "        both = {}\n",
    "        for k in sorted(tuples, key=tuples.get, reverse=True):\n",
    "            if used.intersection(set(k)): continue\n",
    "            both[k] = tuples[k]\n",
    "            for w in k: used.add(w)\n",
    " \n",
    "        #for k in cand:\n",
    "        #    if k not in used or True: both[k] = ranks[k] * self.getI(k)\n",
    " \n",
    "        return both\n",
    " \n",
    "    def summarize(self, ratio = 0.333):\n",
    "        r = self.rank()\n",
    "        ks = sorted(r, key=r.get, reverse=True)[:int(len(r)*ratio)]\n",
    "        return ' '.join(map(lambda k:self.dictCount[k], sorted(ks)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 문장 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t0.08666798879227969\t러시아가 우크라이나 키이우 등을 공습한 것은 군 내부 비판과 블라디미르 푸틴 러시아 대통령의 자존심 때문이라는 분석이 나왔다.\n",
      "5\t0.07029042057278401\t 푸틴 대통령은 이날 러시아 안전보장이사회 회의를 주재하고 크림대교 폭발의 배후로 우크라이나 정보 당국을 겨냥하면서 '이런 종류의 범죄에 대응을 하지 않는 것은 불가능하다'고 말했다.\n",
      "13\t0.06815514561018991\t 그는 이번과 같은 대규모 미사일 공격은 러시아 영토 공격 시 대응으로 남겨둘 것이라고 말했는데 강경파들은 전면전을 원하고 있다.\n",
      "1\t0.06429569851243916\t 영국 가디언지는 10일(현지시간) 푸틴 대통령의 대규모 공습은 국내 군 비판세력, 러시아가 침공에서 실패하고 있다는 사실, 크림대교 폭발 후 상처받은 자존심에 대한 절박한 답변이라고 풀이했다.\n",
      "18\t0.061683938582030896\t 러시아에서 나오는 한 가지 이론은 푸틴 대통령이 악명 높은 새로운 군사령관을 임명함으로써 전쟁에서 국방부의 성과에 대한 분노를 줄이려고 한다는 것이다.\n",
      "12\t0.061574888759916464\t 그러나 푸틴 대통령이 이날 공습으로 얻은 매파들의 호평은 오래가지 않을 수 있다.\n",
      "14\t0.05919188596906117\t 정치 평론가인 세르게이 마르코프는 '러시아 여론은 대규모 공격과 우크라이나군이 사용할 가능성이 있는 인프라 완전파괴를 원한다'고 말했다.\n",
      "17\t0.05865832561198442\t 콜레스니코프 선임 연구원은 '푸틴 대통령으로선 매파와 극보수파의 불만에 대응하는 것이 중요하겠지만 나는 그들의 영향력을 과장하진 않을 것'이라며 '푸틴 자신이 가장 매파적이고 극보수적인 인물'이라고 말했다.\n",
      "3\t0.056361527263808664\t 러시아 전쟁 전문가와 군사 블로거 등은 수개월간 우크라이나를 상대로 전면전을 벌이라고 촉구해왔고 키이우 등의 거리에 시신이 있는 끔찍한 사진이 나오자 지금은 만족해한다.\n",
      "9\t0.05472345827869443\t 푸틴 대통령은 이번 공격이 국방부의 요청에 따라 이뤄졌다고 주장했는데, 이것이 사실이라면 이는 새로운 합동군 총사령관 세르게이 수로비킨의 첫번째 결정이라고 가디언은 전했다.\n",
      "4\t0.0533379713499377\t 최근 러시아군 수뇌부를 비판했던 람잔 카디로프 체첸 공화국 수장은 '(볼로디미르) 젤렌스키(우크라이나 대통령), 우리는 러시아가 아직 제대로 시작도 안했다고 경고했다'라며 '이제 전쟁 진행에 100% 만족한다'고 말했다.\n",
      "6\t0.05242912122178555\t 그러나 드미트로 쿨레바 우크라이나 외무장관은 '러시아는 크림대교 사건 전에도 우크라이나에 계속 미사일 공격을 했다'며 '푸틴은 전투 패배로 절박한 상황이며 전황을 유리하게 바꾸려고 미사일 공포를 사용한다'고 반박했다.\n",
      "7\t0.050792751460970384\t 우크라이나 구조대원들이 10일(현지시간) 수도 키이우 시내에서 러시아군의 미사일 공격을 당한 현장을 조사하고 있다.\n",
      "10\t0.04936775219440786\t 수로비킨 사령관과 함께 일했던 전 국방부 관계자는 가디언지에 '오늘 키이우에서 벌어진 일이 놀랍지 않았다.\n",
      "2\t0.04129078433186044\t 가디언에 따르면 미국 싱크탱크 카네기국제평화재단의 선임 연구원 안드레이 콜레스니코프는 '지금 푸틴이 하는 것은 사소한 복수'라며 '개인적 복수도 있다'고 말했다.\n",
      "8\t0.03864387165489514\t 이날 오전에 키이우 시내에 여러차례 폭발이 발생했다.\n",
      "11\t0.018508021450311614\t 그는 매우 무자비하고 사람 목숨을 신경 쓰지 않는다'며 '그의 손이 우크라이나인의 피로 뒤덮일까 걱정된다'고 말했다.\n",
      "15\t0.01834051904962951\t 한편으론 비판 세력의 목소리는 그다지 의미가 없을 수도 있어 보인다.\n",
      "19\t0.018247250041040032\t 수로비킨 사령관과 2020년까지 함께 일했던 전 공군 중위인 글렙 이리소프는 '수로비킨은 강경파들을 선호하고 와그너 용병회사와도 좋은 관계를 유지한다'며 '그러나 그가 매우 잔인한 동시에 유능한 사령관이지만 모든 문제를 풀 수는 없을 것'이라고 말했다.\n",
      "16\t0.017438679291972764\t 전쟁과 관련한 의사결정 과정은 여전히 불투명하다.\n",
      "러시아가 우크라이나 키이우 등을 공습한 것은 군 내부 비판과 블라디미르 푸틴 러시아 대통령의 자존심 때문이라는 분석이 나왔다.  영국 가디언지는 10일(현지시간) 푸틴 대통령의 대규모 공습은 국내 군 비판세력, 러시아가 침공에서 실패하고 있다는 사실, 크림대교 폭발 후 상처받은 자존심에 대한 절박한 답변이라고 풀이했다.  푸틴 대통령은 이날 러시아 안전보장이사회 회의를 주재하고 크림대교 폭발의 배후로 우크라이나 정보 당국을 겨냥하면서 '이런 종류의 범죄에 대응을 하지 않는 것은 불가능하다'고 말했다.  그는 이번과 같은 대규모 미사일 공격은 러시아 영토 공격 시 대응으로 남겨둘 것이라고 말했는데 강경파들은 전면전을 원하고 있다.\n"
     ]
    }
   ],
   "source": [
    "tr = TextRank()\n",
    "stopword = set([('있', 'VV'), ('하', 'VV'), ('되', 'VV') ])\n",
    "tr.loadSents(RawSentenceReader('test.txt'), lambda sent: filter(lambda x:x not in stopword and x[1] in ('NNG', 'NNP', 'VV', 'VA'), komoran.pos(sent)))\n",
    "# print('Build...')\n",
    "tr.build()\n",
    "ranks = tr.rank()\n",
    "for k in sorted(ranks, key=ranks.get, reverse=True)[:100]:\n",
    "    print(\"\\t\".join([str(k), str(ranks[k]), str(tr.dictCount[k])]))\n",
    "print(tr.summarize(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 키워드 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "크림 대교 5.3471075307174685\n",
      "수로 비킨 5.059425458265688\n",
      "미사일 공격 4.366278277705742\n",
      "푸틴 대통령 3.960813169597578\n",
      "규모 미사일 3.960813169597578\n",
      "군 비판 3.960813169597578\n",
      "규모 공격 3.5553480614894135\n",
      "우크라이나 군 3.2676659890376327\n",
      "이날 러시아 3.044522437723423\n",
      "러시아 전쟁 2.7568403652716422\n",
      "우크라이나 키 2.7568403652716422\n",
      "우크라이나 대통령 2.2868367360259065\n",
      "러시아 대통령 2.063693184711697\n",
      "(('푸틴', 'NNP'), ('대통령', 'NNG'))\t0.156417\n",
      "(('미사일', 'NNG'), ('공격', 'NNG'))\t0.117627\n",
      "(('수로', 'NNP'), ('비킨', 'NNP'))\t0.104941\n",
      "(('크림', 'NNP'), ('대교', 'NNP'))\t0.104452\n",
      "(('러시아', 'NNP'),)\t0.10077\n",
      "(('우크라이나', 'NNP'), ('키', 'NNG'))\t0.0949822\n",
      "(('군', 'NNG'), ('비판', 'NNG'))\t0.0861607\n",
      "(('규모', 'NNG'),)\t0.0472933\n",
      "(('매파', 'NNP'),)\t0.0459871\n",
      "(('이날', 'NNG'),)\t0.0432415\n",
      "(('전쟁', 'NNG'),)\t0.0406895\n",
      "(('국방부', 'NNP'),)\t0.0389833\n",
      "(('가디언', 'NNP'),)\t0.0380954\n",
      "(('말', 'NNG'),)\t0.032053\n"
     ]
    }
   ],
   "source": [
    "tr = TextRank(window=5, coef=1)\n",
    "# print('Load...')\n",
    "stopword = set([('있', 'VV'), ('하', 'VV'), ('되', 'VV'), ('없', 'VV') ])\n",
    "tr.load(RawTaggerReader('test.txt', tagger=komoran), lambda w: w not in stopword and (w[1] in ('NNG', 'NNP', 'VV', 'VA')))\n",
    "# print('Build...')\n",
    "tr.build()\n",
    "kw = tr.extract(0.1)\n",
    "for k in sorted(kw, key=kw.get, reverse=True):\n",
    "    print(\"%s\\t%g\" % (k, kw[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TopicRank "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TopicalPageRank "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PositionRank "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MultipartiteRank  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ExpandRank "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KEA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KeyBERT "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Korean KeyBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "품사 태깅 10개만 출력 : [('러시아', 'Noun'), ('가', 'Josa'), ('우크라이나', 'Noun'), ('키이우', 'Noun'), ('등', 'Noun'), ('을', 'Josa'), ('공습', 'Noun'), ('한', 'Josa'), ('것', 'Noun'), ('은', 'Josa')]\n",
      "명사 추출 : 러시아 우크라이나 키이우 등 공습 것 군 내부 비판 블라디미르 푸틴 러시아 대통령 자존심 때문 분석 영국 가디언 현지 시간 푸틴 대통령 대규모 공습 국내 군 비판 세력 러시아 침공 사실 크림 대교 폭발 후 상처 자존심 대한 절박 답변 풀이 가디언 미국 싱크탱크 카네기 국제 평화 재단 선임 연구원 안드레이 콜레스니코프 지금 푸틴 것 복수 라며 개인 복수 고 말 러시아 전쟁 전문가 군사 블로거 등 개 월간 우크라이나 상대로 면전 벌이 촉구 키이우 등 거리 시신 사진 지금 최근 러시아군 수뇌부 비판 람잔 카디 로프 체첸 공화국 수장 볼 로디 미르 젤 렌스 키 우크라이나 대통령 우리 러시아 제대로 시작 경고 라며 이제 전쟁 진행 고 말 푸틴 대통령 날 러시아 안전보장 이사회 회의 주재 크림 대교 폭발 배후 우크라이나 정보 당국 겨냥 종류 범죄 대응 것 고 말 드미트 쿨 레바 우크라이나 외무 장관 러시아 크림 대교 사건 전 우크라이나 계속 미사일 공격 며 푸틴 전투 패배 절박 상황 전황 미사일 공포 사용 고 반박 우크라이나 구조대 현지 시간 수도 키이우 시내 러시아군 미사일 공격 당한 현장 조사 날 오전 키이우 시내 차례 폭발 발생 푸틴 대통령 이번 공격 국방부 요청 주장 것 합동 총사령관 세르게이 로비킨 첫 결정 가디언 전 로비킨 사령관 일 전 국방부 관계자 가디언 오늘 키이우 그 매우 사람 목숨 신경 며 그 손 우크라이나인 피로 뒤 걱정 고 말 푸틴 대통령 날 공습 매파 호평 가지 수 그 이번 대규모 미사일 공격 러시아 영토 공격 시 대응 둘 것 말 강경 파 면전 정치 평론가 세르게이 마르코프 러시아 여론 대규모 공격 우크라이나 사용 가능성 인프라 완전 파괴 고 말 한편 비판 세력 목소리 그다지 의미 수도 전쟁 관련 의사결정 과정 콜레스니코프 선임 연구원 푸틴 대통령 매파 보수파 불만 대응 것 나 그 영향력 것 라며 푸틴 자신 가장 파적 보수 인물 말 러시아 가지 이론 푸틴 대통령 악명 군 사령관 임명 함 전쟁 국방부 성과 대한 분노 것 로비킨 사령관 일 전 공군 중위 글렙 소프 로비킨 강경 파 선호 너 용병 회사 관계 유지 며 그 매우 동시 사령관 모든 문제 풀 수 것 말\n",
      "trigram 개수:  519\n",
      "trigram 5개 출력:  ['가능성 인프라' '가능성 인프라 완전' '가디언 로비킨' '가디언 로비킨 사령관' '가디언 미국']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 574/574 [00:00<00:00, 261kB/s]\n",
      "Downloading: 100%|██████████| 190/190 [00:00<00:00, 82.5kB/s]\n",
      "Downloading: 100%|██████████| 4.06k/4.06k [00:00<00:00, 1.72MB/s]\n",
      "Downloading: 100%|██████████| 731/731 [00:00<00:00, 303kB/s]\n",
      "Downloading: 100%|██████████| 122/122 [00:00<00:00, 53.1kB/s]\n",
      "Downloading: 100%|██████████| 1.11G/1.11G [00:19<00:00, 55.7MB/s]\n",
      "Downloading: 100%|██████████| 53.0/53.0 [00:00<00:00, 23.2kB/s]\n",
      "Downloading: 100%|██████████| 5.07M/5.07M [00:02<00:00, 2.32MB/s]\n",
      "Downloading: 100%|██████████| 150/150 [00:00<00:00, 64.6kB/s]\n",
      "Downloading: 100%|██████████| 9.10M/9.10M [00:00<00:00, 43.5MB/s]\n",
      "Downloading: 100%|██████████| 527/527 [00:00<00:00, 206kB/s]\n",
      "Downloading: 100%|██████████| 229/229 [00:00<00:00, 101kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['영향력 라며 푸틴', '러시아 전쟁 전문가', '러시아군 수뇌부 비판', '공습 국내 비판', '비판 블라디미르 푸틴']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "okt = Okt()\n",
    "tokenized_doc = okt.pos(STRTexT)\n",
    "tokenized_nouns = ' '.join([word[0] for word in tokenized_doc if word[1] == 'Noun'])\n",
    "\n",
    "print('품사 태깅 10개만 출력 :',tokenized_doc[:10])\n",
    "print('명사 추출 :',tokenized_nouns)\n",
    "\n",
    "n_gram_range = (2, 3)\n",
    "count = CountVectorizer(ngram_range=n_gram_range).fit([tokenized_nouns])\n",
    "candidates = count.get_feature_names_out()\n",
    "\n",
    "print('trigram 개수: ', len(candidates))\n",
    "print('trigram 5개 출력: ', candidates[:5])\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/xlm-r-100langs-bert-base-nli-stsb-mean-tokens')\n",
    "doc_embedding = model.encode([STRTexT])\n",
    "candidate_embeddings = model.encode(candidates)\n",
    "\n",
    "top_n = 5\n",
    "distances = cosine_similarity(doc_embedding, candidate_embeddings)\n",
    "keywords = [candidates[index] for index in distances.argsort()[0][-top_n:]]\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Max Sum Similarity : \n",
    "데이터 쌍 사이의 최대 합 거리는 데이터 쌍 간의 거리가 최대화되는 데이터 쌍으로 정의됨.\n",
    "후보 간의 유사성을 최소화하면서 문서와의 후보 유사성을 극대화하고자 하는 로직임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['개인 복수 러시아', '걱정 푸틴 대통령', '공습 내부 비판', '영향력 라며 푸틴', '러시아 전쟁 전문가', '공습 국내 비판']\n",
      "['내부 비판 블라디미르', '전쟁 국방부 성과', '푸틴 전투 패배', '미사일 공격 푸틴', '러시아 침공 사실', '공습 국내 비판']\n"
     ]
    }
   ],
   "source": [
    "def max_sum_sim(doc_embedding, candidate_embeddings, words, top_n, nr_candidates):\n",
    "    # 문서와 각 키워드들 간의 유사도\n",
    "    distances = cosine_similarity(doc_embedding, candidate_embeddings)\n",
    "\n",
    "    # 각 키워드들 간의 유사도\n",
    "    distances_candidates = cosine_similarity(candidate_embeddings, \n",
    "                                            candidate_embeddings)\n",
    "\n",
    "    # 코사인 유사도에 기반하여 키워드들 중 상위 top_n개의 단어를 pick.\n",
    "    words_idx = list(distances.argsort()[0][-nr_candidates:])\n",
    "    words_vals = [candidates[index] for index in words_idx]\n",
    "    distances_candidates = distances_candidates[np.ix_(words_idx, words_idx)]\n",
    "\n",
    "    # 각 키워드들 중에서 가장 덜 유사한 키워드들간의 조합을 계산\n",
    "    min_sim = np.inf\n",
    "    candidate = None\n",
    "    for combination in itertools.combinations(range(len(words_idx)), top_n):\n",
    "        sim = sum([distances_candidates[i][j] for i in combination for j in combination if i != j])\n",
    "        if sim < min_sim:\n",
    "            candidate = combination\n",
    "            min_sim = sim\n",
    "\n",
    "    return [words_vals[idx] for idx in candidate]\n",
    "\n",
    "\n",
    "print(max_sum_sim(doc_embedding, candidate_embeddings, candidates, top_n=6, nr_candidates=10))\n",
    "print(max_sum_sim(doc_embedding, candidate_embeddings, candidates, top_n=6, nr_candidates=30))  # nr_candidates가 높을수록 다양한 키워드 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Maximal Marginal Relevance : 텍스트 요약 작업에서 중복을 최소화하고 결과의 다양성을 극대화하는 로직. 문서와 가장 유사한 키워드/키프레이즈를 선택한 후 문서와 유사하고 이미 선택된 키워드/키프레이즈와 유사하지 않은 새로운 후보를 반복적으로 선택함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['비판 블라디미르 푸틴', '공습 국내 비판', '러시아 전쟁 전문가', '러시아군 수뇌부 비판', '개인 복수 러시아', '영향력 라며 푸틴', '비판 세력 러시아', '걱정 푸틴 대통령', '공습 내부 비판', '푸틴 대통령 공습']\n",
      "['비판 블라디미르 푸틴', '대규모 공습', '전투 패배 절박', '평화 재단 선임', '거리 시신', '배후 우크라이나 정보', '전문가 군사 블로거', '러시아 침공 사실', '범죄 대응', '보수파 불만 대응']\n"
     ]
    }
   ],
   "source": [
    "def mmr(doc_embedding, candidate_embeddings, words, top_n, diversity):\n",
    "\n",
    "    # 문서와 각 키워드들 간의 유사도가 적혀있는 리스트\n",
    "    word_doc_similarity = cosine_similarity(candidate_embeddings, doc_embedding)\n",
    "\n",
    "    # 각 키워드들 간의 유사도\n",
    "    word_similarity = cosine_similarity(candidate_embeddings)\n",
    "\n",
    "    # 문서와 가장 높은 유사도를 가진 키워드의 인덱스를 추출.\n",
    "    # 만약, 2번 문서가 가장 유사도가 높았다면\n",
    "    # keywords_idx = [2]\n",
    "    keywords_idx = [np.argmax(word_doc_similarity)]\n",
    "\n",
    "    # 가장 높은 유사도를 가진 키워드의 인덱스를 제외한 문서의 인덱스들\n",
    "    # 만약, 2번 문서가 가장 유사도가 높았다면\n",
    "    # ==> candidates_idx = [0, 1, 3, 4, 5, 6, 7, 8, 9, 10 ... 중략 ...]\n",
    "    candidates_idx = [i for i in range(len(words)) if i != keywords_idx[0]]\n",
    "\n",
    "    # 최고의 키워드는 이미 추출했으므로 top_n-1번만큼 아래를 반복.\n",
    "    # ex) top_n = 5라면, 아래의 loop는 4번 반복됨.\n",
    "    for _ in range(top_n - 1):\n",
    "        candidate_similarities = word_doc_similarity[candidates_idx, :]\n",
    "        target_similarities = np.max(word_similarity[candidates_idx][:, keywords_idx], axis=1)\n",
    "\n",
    "        # MMR을 계산\n",
    "        mmr = (1-diversity) * candidate_similarities - diversity * target_similarities.reshape(-1, 1)\n",
    "        mmr_idx = candidates_idx[np.argmax(mmr)]\n",
    "\n",
    "        # keywords & candidates를 업데이트\n",
    "        keywords_idx.append(mmr_idx)\n",
    "        candidates_idx.remove(mmr_idx)\n",
    "\n",
    "    return [words[idx] for idx in keywords_idx]\n",
    "\n",
    "\n",
    "print(mmr(doc_embedding, candidate_embeddings, candidates, top_n=10, diversity=0.2)) # 상대적으로 낮은 diversity값을 설정하면, 기존의 코사인 유사도만 사용한 것과 매우 유사함\n",
    "print(mmr(doc_embedding, candidate_embeddings, candidates, top_n=10, diversity=0.7)) # 상대적으로 높은 diversity값을 설정하면 다양한 키워드를 추출함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a0fc480af1f47fb618343e9d74e4d54da4e469394bb9bebde36f22e938ea4c4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
